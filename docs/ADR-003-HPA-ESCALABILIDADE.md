# ADR-003: Horizontal Pod Autoscaler (HPA) e Estrat√©gia de Escalabilidade

**Status**: Aceito  
**Data**: 2025-12-07  
**Decisores**: Edimilson L. Dutra, Equipe de Arquitetura  
**Relacionado**: ADR-001 (Arquitetura Serverless vs Containers)

---

## üìã Contexto

O sistema de gest√£o de oficina mec√¢nica possui caracter√≠sticas de carga vari√°vel:
- **Picos de tr√°fego**: Hor√°rio comercial (8h-18h) com ~500 req/min
- **Baixo tr√°fego**: Noites e finais de semana com ~10 req/min
- **Sazonalidade**: Varia√ß√£o de 30-40% entre meses (dezembro > janeiro)
- **Crescimento**: Expectativa de crescimento de 1000 para 100.000 clientes em 2 anos

### Requisitos N√£o-Funcionais
1. **Disponibilidade**: 99.9% (8.76h downtime/ano)
2. **Lat√™ncia**: P95 < 500ms para cria√ß√£o de ordem de servi√ßo
3. **Efici√™ncia de Custo**: Minimizar recursos ociosos
4. **Resili√™ncia**: Tolerar falha de 1 pod sem impacto

---

## ‚öñÔ∏è Decis√£o

**Implementar Horizontal Pod Autoscaler (HPA) com as seguintes configura√ß√µes**:

### Configura√ß√£o HPA
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: oficina-service-hpa
  namespace: oficina-service
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: oficina-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 300
```

### Par√¢metros Escolhidos

| Par√¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| **minReplicas** | 2 | Alta disponibilidade: tolera falha de 1 pod |
| **maxReplicas** | 10 | Limite de custos (~$500/m√™s) + capacidade RDS |
| **CPU Target** | 70% | Margem para picos s√∫bitos (30% headroom) |
| **Memory Target** | 80% | Evita OOMKilled, mant√©m buffer |
| **Scale Up Stabilization** | 60s | Evita flapping, responde r√°pido a picos |
| **Scale Down Stabilization** | 300s (5min) | Conservativo: evita scale down prematuro |
| **Scale Up Policy** | Min(50% ou 2 pods) | Crescimento gradual, max 2 pods/min |
| **Scale Down Policy** | 50% a cada 5min | Decrescimento suave |

---

## üéØ Justificativa

### Por que Horizontal Pod Autoscaler?

#### ‚úÖ Pr√≥s

**1. Elasticidade Autom√°tica**
- Escala **automaticamente** baseado em m√©tricas reais (CPU, Memory)
- Responde a picos de tr√°fego em **~60 segundos**
- Reduz custos em per√≠odos de baixa demanda (noites, fins de semana)

**2. Alta Disponibilidade**
- `minReplicas: 2` garante redund√¢ncia
- Pods distribu√≠dos em m√∫ltiplas zonas de disponibilidade (AZs)
- Sem single point of failure

**3. Performance Consistente**
- Target de **70% CPU** mant√©m headroom para bursts
- Evita throttling e degrada√ß√£o de lat√™ncia
- P95 latency mantido abaixo de 500ms

**4. Custo-Efetivo**
- **Scale to zero** n√£o √© necess√°rio (diferente de serverless)
- Paga apenas pelos pods em uso
- Estimativa de economia: **~40%** vs. provisionamento fixo de 10 pods

**5. Simples de Implementar**
- Feature nativa do Kubernetes
- Integra√ß√£o com Metrics Server (j√° instalado)
- Zero c√≥digo adicional na aplica√ß√£o

#### ‚ùå Contras

**1. Lat√™ncia de Scale Up**
- ~60s para adicionar novo pod (image pull + startup)
- Poss√≠vel degrada√ß√£o tempor√°ria durante picos s√∫bitos
- **Mitiga√ß√£o**: `minReplicas: 2` cobre tr√°fego base

**2. Cold Start (JVM)**
- Pods novos t√™m ~10-15s de aquecimento (JIT compilation)
- Primeiras requisi√ß√µes podem ter lat√™ncia +50ms
- **Mitiga√ß√£o**: Readiness probe aguarda aquecimento

**3. Complexidade de Tuning**
- Requer ajuste fino de CPU/Memory targets
- Pode causar flapping se mal configurado
- **Mitiga√ß√£o**: Stabilization windows (60s up, 300s down)

**4. Depend√™ncia do Metrics Server**
- Se Metrics Server falhar, HPA para de escalar
- **Mitiga√ß√£o**: Metrics Server com HA (2 replicas)

---

### Alternativas Consideradas

#### Alternativa 1: Vertical Pod Autoscaler (VPA)

**Descri√ß√£o**: Ajustar recursos (CPU/Memory) de pods existentes dinamicamente.

**‚ùå Rejeitado**:
- Requer **restart** de pods para aplicar mudan√ßas ‚Üí downtime
- N√£o melhora **throughput** (mesmo n√∫mero de pods)
- Incompat√≠vel com HPA (conflito de recursos)

**Quando usar**: Para workloads stateful que n√£o podem escalar horizontalmente.

---

#### Alternativa 2: Cluster Autoscaler Apenas

**Descri√ß√£o**: Escalar apenas nodes do cluster, sem HPA.

**‚ùå Rejeitado**:
- **Lat√™ncia alta**: ~5 minutos para adicionar novo node
- **Granularidade grossa**: Adiciona node inteiro (2 vCPU, 4 GB)
- **Desperd√≠cio**: Pode adicionar node com capacidade excessiva

**Decis√£o**: Usar Cluster Autoscaler **complementar** ao HPA:
- HPA escala pods (r√°pido, fino)
- Cluster Autoscaler adiciona nodes quando cluster est√° cheio

---

#### Alternativa 3: KEDA (Kubernetes Event-Driven Autoscaling)

**Descri√ß√£o**: Escalar baseado em eventos externos (filas, HTTP requests, m√©tricas customizadas).

**‚ùå Rejeitado para agora** (mas considerado para futuro):
- **Complexidade**: Requer instala√ß√£o e configura√ß√£o adicional
- **Overhead**: Adiciona componente externo (KEDA operator)
- **Uso atual**: N√£o temos filas ou eventos que justifiquem

**Quando reconsiderar**:
- Se migrarmos para arquitetura event-driven (SQS, Kafka)
- Se precisarmos escalar baseado em m√©tricas de neg√≥cio (ex: tamanho da fila de ordens)

---

#### Alternativa 4: Provisionamento Fixo (No Autoscaling)

**Descri√ß√£o**: Manter n√∫mero fixo de pods (ex: 5 replicas 24/7).

**‚ùå Rejeitado**:
- **Custo alto**: Paga por 5 pods 24h/dia, mesmo em per√≠odos ociosos
- **Desperd√≠cio**: ~70% de ociosidade em noites e fins de semana
- **Inflex√≠vel**: N√£o responde a picos inesperados

**Custo estimado**:
- Fixo (5 pods): **$245/m√™s**
- HPA (2-10 pods, m√©dia 4): **$150/m√™s** ‚Üí **economia de 39%**

---

## üìä An√°lise Quantitativa

### Simula√ß√£o de Carga

**Cen√°rio 1: Tr√°fego Normal (Dia √∫til)**
```
Hora         | Req/min | CPU/pod | Pods (HPA) | Pods (Fixo)
-------------|---------|---------|------------|------------
00:00-06:00  |   10    |   5%    |     2      |     5
06:00-08:00  |   50    |  25%    |     2      |     5
08:00-12:00  |  500    |  70%    |     8      |     5 (overload!)
12:00-14:00  |  300    |  45%    |     5      |     5
14:00-18:00  |  500    |  70%    |     8      |     5 (overload!)
18:00-22:00  |  100    |  15%    |     2      |     5
22:00-24:00  |   20    |   8%    |     2      |     5
-------------|---------|---------|------------|------------
M√©dia di√°ria |         |         |    4.3     |     5
```

**Resultado**:
- HPA: **4.3 pods em m√©dia** (economia de 14% vs fixo)
- Fixo: **Overload** em hor√°rios de pico (lat√™ncia degrada)

---

**Cen√°rio 2: Black Friday (Pico extremo)**
```
Hora         | Req/min | CPU/pod | Pods (HPA) | Pods (Fixo)
-------------|---------|---------|------------|------------
10:00-12:00  | 1000    |  140%   |    10      |     5 (crash!)
12:00-14:00  |  800    |  110%   |    10      |     5 (crash!)
14:00-16:00  | 1200    |  165%   |    10      |     5 (crash!)
```

**Resultado**:
- HPA: Escala at√© **maxReplicas: 10**, mant√©m sistema est√°vel
- Fixo: **Colapso total** (pods crasham por OOMKilled)

---

### C√°lculo de Custos

**Premissas**:
- EC2 t3.medium: 2 vCPU, 4 GB RAM = **$0.0416/hora**
- 1 pod consome: ~500m CPU, 512 Mi RAM
- 1 node suporta: ~3 pods (com overhead K8s)

**Custo Mensal (HPA)**:
```
Pods m√©dios: 4.3
Nodes necess√°rios: ceil(4.3 / 3) = 2 nodes
Custo: 2 nodes √ó $0.0416/h √ó 730h = $60.74

+ Picos (8 pods):
  3 nodes √ó $0.0416/h √ó 200h/m√™s = $24.96

Total: $85.70/m√™s
```

**Custo Mensal (Fixo - 5 pods)**:
```
Nodes necess√°rios: ceil(5 / 3) = 2 nodes
Custo: 2 nodes √ó $0.0416/h √ó 730h = $60.74/m√™s
```

**Custo Mensal (Fixo - 10 pods para suportar picos)**:
```
Nodes necess√°rios: ceil(10 / 3) = 4 nodes
Custo: 4 nodes √ó $0.0416/h √ó 730h = $121.48/m√™s
```

**Compara√ß√£o**:
| Estrat√©gia | Custo/m√™s | Suporta Picos? | Economia |
|------------|-----------|----------------|----------|
| HPA (2-10) | **$85.70** | ‚úÖ Sim | Baseline |
| Fixo (5 pods) | $60.74 | ‚ùå N√£o | -$24.96 (mas falha em picos!) |
| Fixo (10 pods) | $121.48 | ‚úÖ Sim | +$35.78 (desperd√≠cio) |

**Conclus√£o**: HPA oferece melhor **custo-benef√≠cio** quando consideramos picos.

---

## üîß Implementa√ß√£o

### 1. Pr√©-requisitos

**Metrics Server** (instalado no EKS):
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

**Verificar**:
```bash
kubectl top nodes
kubectl top pods -n oficina-service
```

---

### 2. Resource Requests & Limits

**Deployment** (`oficina-service/k8s/base/deployment.yaml`):
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oficina-service
spec:
  replicas: 2  # Sobrescrito pelo HPA
  template:
    spec:
      containers:
      - name: app
        image: oficina-service:latest
        resources:
          requests:
            cpu: "500m"      # 0.5 vCPU
            memory: "512Mi"  # 512 MiB
          limits:
            cpu: "1000m"     # 1 vCPU
            memory: "1Gi"    # 1 GiB
```

**Por que esses valores?**
- **Requests**: Garantia m√≠nima para o pod rodar
- **Limits**: M√°ximo que pode usar (evita noisy neighbor)
- **Ratio 1:2**: Permite burst tempor√°rio (ex: GC spikes)

---

### 3. Criar HPA

```bash
kubectl apply -f k8s/base/hpa.yaml
```

**Verificar**:
```bash
kubectl get hpa -n oficina-service

NAME                   REFERENCE                     TARGETS          MINPODS   MAXPODS   REPLICAS
oficina-service-hpa    Deployment/oficina-service    45%/70%, 60%/80%    2         10        2
```

---

### 4. Testar Escalabilidade

**Gerar carga**:
```bash
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh

# Dentro do pod
while true; do wget -q -O- http://oficina-service.oficina-service.svc.cluster.local/api/v1/work-orders; done
```

**Observar escalamento**:
```bash
watch -n 5 kubectl get hpa,pods -n oficina-service
```

**Esperado**:
- CPU aumenta para ~80%
- Ap√≥s 60s, HPA adiciona 1-2 pods
- Pods novos ficam Ready ap√≥s ~30s
- CPU normaliza para ~60%

---

### 5. Cluster Autoscaler (Complementar)

**Se HPA tentar escalar mas n√£o h√° nodes dispon√≠veis**, Cluster Autoscaler adiciona node.

**Instala√ß√£o** (Terraform `infra-kubernetes-terraform/modules/eks/cluster-autoscaler.tf`):
```hcl
resource "kubernetes_deployment" "cluster_autoscaler" {
  metadata {
    name      = "cluster-autoscaler"
    namespace = "kube-system"
  }
  
  spec {
    replicas = 1
    
    selector {
      match_labels = {
        app = "cluster-autoscaler"
      }
    }
    
    template {
      metadata {
        labels = {
          app = "cluster-autoscaler"
        }
      }
      
      spec {
        container {
          name  = "cluster-autoscaler"
          image = "k8s.gcr.io/autoscaling/cluster-autoscaler:v1.28.0"
          
          command = [
            "./cluster-autoscaler",
            "--cloud-provider=aws",
            "--namespace=kube-system",
            "--node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/${var.cluster_name}",
            "--balance-similar-node-groups",
            "--skip-nodes-with-system-pods=false"
          ]
        }
      }
    }
  }
}
```

**Node Group** (Auto Scaling Group):
```hcl
resource "aws_autoscaling_group" "eks_nodes" {
  name                = "${var.cluster_name}-eks-nodes"
  min_size            = 2
  max_size            = 10
  desired_capacity    = 3
  vpc_zone_identifier = var.private_subnets
  
  tag {
    key                 = "k8s.io/cluster-autoscaler/enabled"
    value               = "true"
    propagate_at_launch = true
  }
  
  tag {
    key                 = "k8s.io/cluster-autoscaler/${var.cluster_name}"
    value               = "owned"
    propagate_at_launch = true
  }
}
```

---

## üìà Monitoramento

### M√©tricas do HPA (New Relic)

**NRQL Queries**:
```sql
-- N√∫mero de replicas ao longo do tempo
SELECT latest(desiredReplicas), latest(currentReplicas)
FROM K8sHorizontalPodAutoscalerSample
WHERE clusterName = 'oficina-eks-cluster'
AND horizontalPodAutoscalerName = 'oficina-service-hpa'
FACET dateOf(timestamp)
TIMESERIES 5 minutes
SINCE 1 day ago

-- CPU/Memory usage vs target
SELECT average(cpuUsedCores) / average(cpuRequestedCores) * 100 AS 'CPU %',
       average(memoryUsedBytes) / average(memoryRequestedBytes) * 100 AS 'Memory %'
FROM K8sContainerSample
WHERE deploymentName = 'oficina-service'
FACET podName
TIMESERIES 1 minute
SINCE 1 hour ago

-- Scale events
SELECT count(*)
FROM K8sEvent
WHERE objectKind = 'HorizontalPodAutoscaler'
AND objectName = 'oficina-service-hpa'
AND reason IN ('ScaledUp', 'ScaledDown')
FACET reason
TIMESERIES 1 hour
SINCE 1 day ago
```

---

### Alertas

**Alert 1: HPA Maxed Out**
```yaml
name: HPA Maxed Out - oficina-service
description: HPA atingiu maxReplicas, pode precisar aumentar limite
nrql: |
  SELECT latest(currentReplicas)
  FROM K8sHorizontalPodAutoscalerSample
  WHERE horizontalPodAutoscalerName = 'oficina-service-hpa'
threshold:
  critical: currentReplicas >= 10
  duration: 10 minutes
notification: Slack #ops-alerts
```

**Alert 2: Pods em CrashLoopBackOff**
```yaml
name: Pods Crashing - oficina-service
description: Pods n√£o est√£o iniciando corretamente
nrql: |
  SELECT uniqueCount(podName)
  FROM K8sPodSample
  WHERE deploymentName = 'oficina-service'
  AND status = 'Failed'
threshold:
  critical: count > 0
  duration: 5 minutes
notification: PagerDuty
```

**Alert 3: CPU/Memory Acima do Target**
```yaml
name: Resource Usage High - oficina-service
description: Pods consistentemente acima do target (pode escalar)
nrql: |
  SELECT average(cpuUsedCores) / average(cpuRequestedCores) * 100 AS cpu_pct
  FROM K8sContainerSample
  WHERE deploymentName = 'oficina-service'
threshold:
  critical: cpu_pct > 85
  duration: 10 minutes
notification: Slack #ops-alerts
```

---

## üß™ Testes de Carga

### Teste 1: Scale Up Gradual

**Objetivo**: Verificar se HPA escala corretamente sob carga crescente.

**Procedimento**:
```bash
# Usar Apache Bench
ab -n 100000 -c 100 -H "Authorization: Bearer TOKEN" \
   http://api.oficina.com/api/v1/work-orders
```

**Resultado Esperado**:
1. Tr√°fego aumenta ‚Üí CPU sobe para 80%
2. Ap√≥s 60s, HPA adiciona pods
3. Novos pods ficam Ready em ~30s
4. CPU normaliza para ~60%

---

### Teste 2: Scale Down Conservativo

**Objetivo**: Verificar se HPA n√£o faz scale down prematuro.

**Procedimento**:
1. Gerar carga por 5 minutos (8 pods)
2. Parar carga abruptamente
3. Observar tempo at√© scale down

**Resultado Esperado**:
- Aguarda **5 minutos** (stabilizationWindowSeconds)
- Remove pods gradualmente (50% a cada 5 min)
- `8 ‚Üí 4 ‚Üí 2` (total: 10 minutos)

---

### Teste 3: Burst Extremo (Black Friday)

**Objetivo**: Verificar comportamento sob carga extrema.

**Procedimento**:
```bash
# JMeter com 1000 threads
jmeter -n -t load-test.jmx -l results.jtl
```

**Resultado Esperado**:
- HPA escala rapidamente at√© `maxReplicas: 10`
- Cluster Autoscaler adiciona nodes se necess√°rio (~5 min)
- P95 latency se mant√©m < 1s (aceit√°vel sob carga extrema)

---

## üéì Li√ß√µes Aprendidas

### ‚úÖ Boas Pr√°ticas

1. **Sempre defina `requests` e `limits`**
   - HPA depende de `requests` para calcular CPU %
   - Sem `limits`, pod pode consumir recursos ilimitados (noisy neighbor)

2. **Use stabilization windows**
   - Evita flapping (scale up/down r√°pido demais)
   - `scaleDown: 300s` √© conservador mas seguro

3. **minReplicas >= 2 para HA**
   - Tolera falha de 1 pod
   - Deployment pode fazer rolling update sem downtime

4. **Teste sob carga antes de produ√ß√£o**
   - Simule Black Friday em staging
   - Ajuste targets baseado em m√©tricas reais

5. **Monitore scale events**
   - Alertas quando HPA atinge maxReplicas
   - Investigue se √© pico leg√≠timo ou leak de recursos

---

### ‚ùå Armadilhas a Evitar

1. **Targets muito agressivos (ex: CPU 95%)**
   - Deixa zero headroom para bursts
   - Causa lat√™ncia alta em picos s√∫bitos

2. **minReplicas = 1 (sem HA)**
   - Single point of failure
   - Downtime durante deploy ou restart

3. **Ignorar cold start da JVM**
   - Pods novos demoram ~15s para aquecer
   - Considerar `preStopHook` para graceful shutdown

4. **Escalar apenas por CPU (ignorar Memory)**
   - Apps Java podem ter memory leak
   - OOMKilled causa crash mesmo com CPU baixo

5. **N√£o configurar Cluster Autoscaler**
   - HPA n√£o consegue adicionar pods se cluster est√° cheio
   - Pods ficam em estado `Pending`

---

## üîÆ Pr√≥ximos Passos

### Curto Prazo (3 meses)
1. **Custom Metrics**: Escalar baseado em m√©tricas de neg√≥cio
   ```yaml
   metrics:
   - type: Pods
     pods:
       metric:
         name: http_requests_per_second
       target:
         type: AverageValue
         averageValue: "1000"
   ```

2. **Predictive Autoscaling**: Usar ML para antecipar picos
   - New Relic Applied Intelligence
   - AWS Predictive Scaling (se migrar para ECS)

### M√©dio Prazo (6 meses)
3. **KEDA**: Escalar baseado em filas (se adotarmos event-driven)
   ```yaml
   triggers:
   - type: aws-sqs-queue
     metadata:
       queueURL: https://sqs.us-east-1.amazonaws.com/.../orders-queue
       queueLength: "5"
       awsRegion: "us-east-1"
   ```

4. **Vertical Pod Autoscaler (VPA)**: Para workloads espec√≠ficos
   - Usar em conjunto com HPA (com cuidado)
   - Apenas para pods stateful que n√£o podem escalar horizontalmente

### Longo Prazo (12 meses)
5. **Multi-Cluster**: Escalar entre regi√µes
   - Usar Route 53 para geo-routing
   - EKS clusters em us-east-1 e sa-east-1

6. **Serverless Complement**: Mover cargas spike-heavy para Lambda
   - Ex: Relat√≥rios ass√≠ncronos
   - Processamento de imagens

---

## üìö Refer√™ncias

- **Kubernetes HPA Docs**: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
- **AWS EKS Best Practices**: https://aws.github.io/aws-eks-best-practices/scalability/docs/
- **CNCF Autoscaling Guide**: https://www.cncf.io/blog/2021/09/01/autoscaling-in-kubernetes/
- **New Relic K8s Monitoring**: https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/

---

## üìù Hist√≥rico de Revis√µes

| Data | Vers√£o | Mudan√ßa | Autor |
|------|--------|---------|-------|
| 2025-12-07 | 1.0 | Cria√ß√£o inicial | Edimilson L. Dutra |
| - | - | - | - |

---

**Documento aprovado por**: Equipe de Arquitetura  
**Pr√≥xima revis√£o**: 2026-06-07 (6 meses)
